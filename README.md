### Book: A simple guide to retrieval augmented Generation


#### Chapters

##### Chapter I

- LLM and the need for RAG.



##### Chapter II

- RAG Systems and their design




##### Chapter III

- Generation of index pipeline
- Data Loading: We will use LangChain
- Data chunking: Offers advantages: 
  
   Context window of LLms, context window size (total number of tokens that an LLM can process)
   Lost-in-the-middle problem: The accuray decline dramatically.
   Ease of search: More efficient to search in smaller set
   
- Embeddings model: Is a design pattern that is extremely helpful in the fields of data sciente.
The goal of an embeddig model is to convert words into n-dimensional vectors.

Embeddings:
- Word2Vec: is a shallow-neural-network-based model for learning word embeddings
- Glove: global vectors for word representations is an usupervised learning technique 
- FastText: is an extension of Word2Vec
- ElMo: best for question answering and sentiment analysis taks
- Bert: Bidirectional Encoder Representations from Transformes

#### Chapter IV

Retrieval, Augmentation, and LLM cycle

 
